# 信息检索相关指标概念


## 1. TF-IDF(term freqency - inverse document freqency)

**term freqency:**
描述一个词在文档中的重要性，很自然的使用这个词在文档中的频率：

$$ tf(f,d) = \frac{f(t,d)}{\sum_t(f(t,d))},即单词出现的次数除以单词数$$
也可以使用log的函数:

$$tf(f,d) = log(1+f_{td})$$

**inverse document frequncy**:描述一个词在整个语料库中的重要性，如果一个单词在整个的语料库中出现次数太多，则其重要性不高，如中文中"的"基本本个文档中都会出现多次，这基本上是无意义的单词,逆文档频率的公式为:

$$idf(f,d) = log(\frac{N}{n_t})$$
其中，N代表文档的总数，$n_t$代表出现单词t的文档数，因此当出现文档t的总数越少是，说明单词t的重要性越高。

而tf-idf是用两者的乘积作为最后的单词权重的(term weighting)

## 2. BM-25
bm25是对tf-idf的修正,tf-idf仅仅是对tf*idf，但是其会有一个问题是tf的值会随着单词的增加而无限制的增加，我们认为一个词在文本中的词频无论是50还是100，都说明文本与这个词有关，但相关度不可能是两倍关系，因此需要修改tf的这一部分.

给定一个query Q,其包含n个单词$q_1,...q_n$，则其bm25的值定义为：


$$score(Q,D) = \sum_i^nIDF(q_i).\frac{f(q_i,D)(k_1+1)}{f(q_i,D) + k_1(1-b+\frac{|D|}{avgdl})}$$

其中， $f(q_i,D)$为tf值，可以看到其对tf进行限制，|D|为文档长度，avgdl:平均文档长度，默认值 k=[1.2,2.0],b=0.75

下面是一个简单的代码实现:
```
//公式参考维基百科
//输入形式query:[数字山谷:[tf idf] 滴滴大厦:[tf idf]
//doc:一样的形式
func SimBowBm25(queryTFIDF, docTFIDF map[string][2]float64, field string) (score float64) {
	docLenFloat := float64(len(docTFIDF)) // 用分词后的词数当文档长度
	score = 0.0
	for term, _ := range queryTFIDF {
		if matchDocTerm, ok := docTFIDF[term]; ok {
			termTF := matchDocTerm[0]
			termIDF := matchDocTerm[1]
			termFreqInD := termTF * 1.0 / docLenFloat
			numerator := termFreqInD * (g_ltr_bm25_k1 + 1)
			denominator := termFreqInD + g_ltr_bm25_k1*
				(1-g_ltr_bm25_b+g_ltr_bm25_b*docLenFloat/g_ltr_bm25_avgDocLen[field])
			termScore := termIDF * numerator / denominator
			score += termScore
		}
	}
	return score
}
```


参考资料: 

- [python根据BM25实现文本检索](https://zhuanlan.zhihu.com/p/32245748)
- [Okapi BM25](https://en.wikipedia.org/wiki/Okapi_BM25)