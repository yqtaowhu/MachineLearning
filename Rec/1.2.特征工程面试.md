- [特征工程面试问题汇总](#特征工程面试问题汇总)
    - [1. 用物料的后验消费数据做召回存在“幸存者偏差”？能将这些消费数据用于排序吗？](#1-用物料的后验消费数据做召回存在幸存者偏差能将这些消费数据用于排序吗)
    - [2.使用物料的后验消费数据做召回，会放大“马太效应”，对新物料不友好，如何缓解？](#2使用物料的后验消费数据做召回会放大马太效应对新物料不友好如何缓解)
    - [3.解释什么是bias特征？你能举出哪些bias特征的例子？](#3解释什么是bias特征你能举出哪些bias特征的例子)
    - [bias特征怎样接入模型？能否和其他正常特征一起喂入DNN底层？为什么？](#bias特征怎样接入模型能否和其他正常特征一起喂入dnn底层为什么)
    - [某男性新用户对“体育”这个分类的喜好程度未知，如何填充？](#某男性新用户对体育这个分类的喜好程度未知如何填充)
    - [标准化](#标准化)
    - [某个物料曝光2次，被点击1次，如何计算它的CTR?](#某个物料曝光2次被点击1次如何计算它的ctr)


# 特征工程面试问题汇总

### 1. 用物料的后验消费数据做召回存在“幸存者偏差”？能将这些消费数据用于排序吗？
- 使用后验特征肯定有偏差，因为item后验好，说明推荐适合的人，并不一定适合所有人。
- 适合： 通过召回、粗排后，基本与用户有关，后验特征有参考意义
- 容易产生马太效应，好->推荐->好, 不利于冷启动


### 2.使用物料的后验消费数据做召回，会放大“马太效应”，对新物料不友好，如何缓解？

流量保护期: 平均点击率提升，单独召回通道，排序阈值降权等。。。

1. 特征工程修正
- 新物料(点击率)，均值，中位数填充
- 冷启动的特征， 标记是不是冷启动
- 时间衰减特征: 对历史高热进行衰减

2. 召回策略补偿
- 多路召回
- 新物料流量保护
- 探索与利用

3. 模型结果优化
- 对ctr等特征进行正则抑制
- 双胎对偶结果： 减少对后验数据依赖

4. 数据闭环
- 监控新数据占比，触发保护

### 3.解释什么是bias特征？你能举出哪些bias特征的例子？

在推荐系统或机器学习模型中，**Bias特征**是指那些可能引入系统性偏差（systematic bias）的特征。这些偏差可能会导致模型对某些群体、类别或情况产生不公平或不准确的预测。
1. **位置偏差（Position Bias）**
   - 示例：用户更倾向于点击出现在页面顶部的物品，即使它们不是最相关的。
   - 影响：模型可能会误认为排在前面的物品天然更受欢迎，从而强化这种偏差。

2. **曝光偏差（Exposure Bias）**
   - 示例：只有被推荐过的物品才有点击数据，未曝光的物品没有反馈。
   - 影响：模型无法区分“用户不喜欢”和“用户没看到”。

3. **时间偏差（Temporal Bias）**
   - 示例：新上线的物料缺乏历史数据，老物料因为积累数据多而更容易被推荐。
   - 影响：形成马太效应，不利于冷启动。

4. **流行度偏差（Popularity Bias）**
   - 示例：热门物品因历史点击高而持续被推荐，冷门物品难以获得曝光。
   - 影响：推荐结果趋同，多样性下降。

5. **用户行为的历史偏差（Historical Bias）**
   - 示例：基于用户过去的行为做推荐，可能导致兴趣固化，无法发现新兴趣。
   - 影响：推荐结果不够个性化或动态。

6. **标签偏差（Label Bias）**
   - 示例：训练数据中正样本比例过高或过低，导致模型对真实分布估计不准。
   - 影响：评估指标失真，模型泛化能力差。

*如何处理Bias特征？*

- **特征工程修正**：如加入时间衰减因子、填充缺失值、添加是否冷启动标记等。
- **模型层面建模**：使用双塔模型、对抗训练、去偏损失函数等方法减少对bias特征的依赖。
- **策略补偿**：多路召回、探索与利用机制、流量保护期等。
- **评估与监控**：设计无偏评估指标，监控新物料/冷启动效果，构建数据闭环。



### bias特征怎样接入模型？能否和其他正常特征一起喂入DNN底层？为什么？

Bias特征可以和其他正常特征一起喂入DNN底层，但必须配合去偏策略和监控机制，否则容易引发系统性偏差问题。
可以主要讲下position bias, 双塔结果，至于其他的bias，如后验特征，一般直接加入NN中

### 某男性新用户对“体育”这个分类的喜好程度未知，如何填充？

本题考查缺失值处理，下面3个方法是必须要会的

1. 使用该全体的平均值或中位数
2. 训练模型，预测缺失值
3. 分桶，给缺失值一个单独的分桶


### 标准化
对观看次数、观看时长这样的特征，如何做标准化？
为了防止一个变量太大(长尾数据)，一般要进行log、开方在进行z-score标准化
- z-score
- min-max


### 某个物料曝光2次，被点击1次，如何计算它的CTR?

CTR（Click-Through Rate，点击率）是推荐系统中常用的评估指标之一，表示一个物料被点击的概率。

一、基础公式

$$
CTR = \frac{\text{点击次数}}{\text{曝光次数}}
$$


二、实际应用中的优化：拉普拉斯平滑（Laplace Smoothing）

在真实场景中，尤其当曝光次数较少时，原始CTR估计会有较大方差。为了防止小样本带来的偏差，通常使用**拉普拉斯平滑（Laplace Smoothing）**：

$$
CTR_{smoothed} = \frac{\text{点击次数} + \alpha}{\text{曝光次数} + \beta}
$$

其中：
- $\alpha$ 和 $\beta$ 是平滑参数，通常取经验值，如 $\alpha=1, \beta=10$
- 或者用全局平均CTR作为参考值进行平滑

三、进阶方法：贝叶斯 平滑（Bayesian Smoothing）

更高级的做法是使用**贝叶斯平滑**，将全局先验信息考虑进去：

$$
CTR_{bayes} = \frac{\text{点击次数} + G \cdot CTR_{global}}{\text{曝光次数} + G}
$$

其中：
- $CTR_{global}$：整个系统的平均CTR
- $G$：一个权重参数，控制先验的影响力


四、总结

| 方法 | 公式 | 适用场景 |
|------|------|----------|
| 原始CTR | `click / exposure` | 曝光量大时使用 |
| 拉普拉斯平滑 | `(click + α) / (exposure + β)` | 曝光量少时防抖动 |
| 贝叶斯平滑 | `(click + G * global_ctr) / (exposure + G)` | 工业界大规模推荐系统 |